{"env_info": "sys.platform: win32\nPython: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\nCUDA available: True\nGPU 0: NVIDIA GeForce GTX 1050\nCUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2\nNVCC: Cuda compilation tools, release 10.2, V10.2.8\nMSVC: \u7528\u4e8e x64 \u7684 Microsoft (R) C/C++ \u4f18\u5316\u7f16\u8bd1\u5668 19.34.31937 \u7248\nGCC: n/a\nPyTorch: 1.10.0+cu102\nPyTorch compiling details: PyTorch built with:\n  - C++ Version: 199711\n  - MSVC 192829337\n  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n  - OpenMP 2019\n  - LAPACK is enabled (usually provided by MKL)\n  - CPU capability usage: AVX2\n  - CUDA Runtime 10.2\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 7.6.5\n  - Magma 2.5.4\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=C:/w/b/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/w/b/windows/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, \n\nTorchVision: 0.11.0+cu102\nOpenCV: 4.7.0\nMMCV: 1.7.0\nMMCV Compiler: MSVC 192829924\nMMCV CUDA Compiler: 10.2\nMMClassification: 0.25.0+3d4f80d", "seed": 1974395880, "mmcls_version": "0.25.0", "config": "model = dict(\n    type='ImageClassifier',\n    backbone=dict(\n        type='ResNet',\n        depth=18,\n        num_stages=4,\n        out_indices=(3, ),\n        style='pytorch'),\n    neck=dict(type='GlobalAveragePooling'),\n    head=dict(\n        type='LinearClsHead',\n        num_classes=5,\n        in_channels=512,\n        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n        topk=(1, )))\ndataset_type = 'ImageNet'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='RandomResizedCrop', size=224),\n    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='ImageToTensor', keys=['img']),\n    dict(type='ToTensor', keys=['gt_label']),\n    dict(type='Collect', keys=['img', 'gt_label'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='Resize', size=(256, -1)),\n    dict(type='CenterCrop', crop_size=224),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='ImageToTensor', keys=['img']),\n    dict(type='Collect', keys=['img'])\n]\ndata = dict(\n    samples_per_gpu=32,\n    workers_per_gpu=2,\n    train=dict(\n        type='ImageNet',\n        data_prefix='',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='RandomResizedCrop', size=224),\n            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='ToTensor', keys=['gt_label']),\n            dict(type='Collect', keys=['img', 'gt_label'])\n        ],\n        ann_file='data/train.txt',\n        classes='data/classes.txt'),\n    val=dict(\n        type='ImageNet',\n        data_prefix='',\n        ann_file='data/val.txt',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='Resize', size=(256, -1)),\n            dict(type='CenterCrop', crop_size=224),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ],\n        classes='data/classes.txt'),\n    test=dict(\n        type='ImageNet',\n        data_prefix='data/imagenet/val',\n        ann_file='data/imagenet/meta/val.txt',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='Resize', size=(256, -1)),\n            dict(type='CenterCrop', crop_size=224),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ]))\nevaluation = dict(\n    interval=1, metric='accuracy', metric_options=dict(topk=(1, )))\ncheckpoint_config = dict(interval=1)\nlog_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'checkpoints/resnet18_batch256_imagenet_20200708-34ab8f90.pth'\nresume_from = None\nworkflow = [('train', 1)]\noptimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=None)\nlr_config = dict(policy='step', step=[1])\nrunner = dict(type='EpochBasedRunner', max_epochs=100)\nwork_dir = 'work/resnet18_b32_flower'\ngpu_ids = [0]\ndevice = 'cuda'\nseed = 1974395880\n", "CLASSES": ["daisy", "dandelion", "rose", "sunflower", "tulip"]}
{"mode": "val", "epoch": 1, "iter": 18, "lr": 0.001, "accuracy_top-1": 91.78322}
{"mode": "val", "epoch": 2, "iter": 18, "lr": 0.0001, "accuracy_top-1": 90.90909}
{"mode": "val", "epoch": 3, "iter": 18, "lr": 0.0001, "accuracy_top-1": 92.48252}
{"mode": "val", "epoch": 4, "iter": 18, "lr": 0.0001, "accuracy_top-1": 92.30769}
{"mode": "val", "epoch": 5, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.35664}
{"mode": "val", "epoch": 6, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.35664}
{"mode": "val", "epoch": 7, "iter": 18, "lr": 0.0001, "accuracy_top-1": 92.48252}
{"mode": "val", "epoch": 8, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.40559}
{"mode": "val", "epoch": 9, "iter": 18, "lr": 0.0001, "accuracy_top-1": 92.65734}
{"mode": "val", "epoch": 10, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.18182}
{"mode": "val", "epoch": 11, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 12, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 13, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.53147}
{"mode": "val", "epoch": 14, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.18182}
{"mode": "val", "epoch": 15, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 16, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.35664}
{"mode": "val", "epoch": 17, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 18, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.007}
{"mode": "val", "epoch": 19, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.53147}
{"mode": "val", "epoch": 20, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.35664}
{"mode": "val", "epoch": 21, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.35664}
{"mode": "val", "epoch": 22, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 23, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 24, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 25, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 26, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 27, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 28, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 29, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 30, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 31, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 32, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.18182}
{"mode": "val", "epoch": 33, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 34, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.18182}
{"mode": "val", "epoch": 35, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 36, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.23077}
{"mode": "val", "epoch": 37, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 38, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 39, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 40, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.53147}
{"mode": "val", "epoch": 41, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 42, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.23077}
{"mode": "val", "epoch": 43, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 44, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.40559}
{"mode": "val", "epoch": 45, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 46, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 47, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.23077}
{"mode": "val", "epoch": 48, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.58042}
{"mode": "val", "epoch": 49, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.58042}
{"mode": "val", "epoch": 50, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 51, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 52, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.23077}
{"mode": "val", "epoch": 53, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.58042}
{"mode": "val", "epoch": 54, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 55, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.23077}
{"mode": "val", "epoch": 56, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 57, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 58, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.40559}
{"mode": "val", "epoch": 59, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 60, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.58042}
{"mode": "val", "epoch": 61, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.23077}
{"mode": "val", "epoch": 62, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 63, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 64, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 65, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.23077}
{"mode": "val", "epoch": 66, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 67, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 68, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.40559}
{"mode": "val", "epoch": 69, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 70, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.58042}
{"mode": "val", "epoch": 71, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 72, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.40559}
{"mode": "val", "epoch": 73, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 74, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 75, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 76, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.93007}
{"mode": "val", "epoch": 77, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
{"mode": "val", "epoch": 78, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.23077}
{"mode": "val", "epoch": 79, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.58042}
{"mode": "val", "epoch": 80, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.70629}
{"mode": "val", "epoch": 81, "iter": 18, "lr": 0.0001, "accuracy_top-1": 93.88112}
{"mode": "val", "epoch": 82, "iter": 18, "lr": 0.0001, "accuracy_top-1": 94.05595}
